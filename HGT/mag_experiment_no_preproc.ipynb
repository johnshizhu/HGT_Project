{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Academic Graph Dataset Experiment\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code opens the Microsoft Academic Graph Dataset and trains HGT\n",
    "Based on code provided by original HGT paper\n",
    "'''\n",
    "import torch\n",
    "from hgt import *\n",
    "from hgt_utils import *\n",
    "from model import *\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.nodeproppred import Evaluator\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "import sys\n",
    "\n",
    "print(\"Microsoft Academic Graph Dataset Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Data from Open Graph Benchmark ...\n",
      "... Retrieval complete\n",
      "Data(\n",
      "  num_nodes_dict={\n",
      "    author=1134649,\n",
      "    field_of_study=59965,\n",
      "    institution=8740,\n",
      "    paper=736389,\n",
      "  },\n",
      "  edge_index_dict={\n",
      "    (author, affiliated_with, institution)=[2, 1043998],\n",
      "    (author, writes, paper)=[2, 7145660],\n",
      "    (paper, cites, paper)=[2, 5416271],\n",
      "    (paper, has_topic, field_of_study)=[2, 7505078],\n",
      "  },\n",
      "  x_dict={ paper=[736389, 128] },\n",
      "  node_year={ paper=[736389, 1] },\n",
      "  edge_reltype={\n",
      "    (author, affiliated_with, institution)=[1043998, 1],\n",
      "    (author, writes, paper)=[7145660, 1],\n",
      "    (paper, cites, paper)=[5416271, 1],\n",
      "    (paper, has_topic, field_of_study)=[7505078, 1],\n",
      "  },\n",
      "  y_dict={ paper=[736389, 1] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving Data from Open Graph Benchmark ...\")\n",
    "\n",
    "# Get dataset using Pytorch Geometric Loader\n",
    "dataset = PygNodePropPredDataset(name='ogbn-mag')\n",
    "print(\"... Retrieval complete\")\n",
    "data = dataset[0] # pyg graph object\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(\n",
      "  num_nodes_dict={\n",
      "    author=1134649,\n",
      "    field_of_study=59965,\n",
      "    institution=8740,\n",
      "    paper=736389,\n",
      "  },\n",
      "  edge_index_dict={\n",
      "    (author, affiliated_with, institution)=[2, 1043998],\n",
      "    (author, writes, paper)=[2, 7145660],\n",
      "    (paper, cites, paper)=[2, 5416271],\n",
      "    (paper, has_topic, field_of_study)=[2, 7505078],\n",
      "  },\n",
      "  x_dict={ paper=[736389, 128] },\n",
      "  node_year={ paper=[736389, 1] },\n",
      "  edge_reltype={\n",
      "    (author, affiliated_with, institution)=[1043998, 1],\n",
      "    (author, writes, paper)=[7145660, 1],\n",
      "    (paper, cites, paper)=[5416271, 1],\n",
      "    (paper, has_topic, field_of_study)=[7505078, 1],\n",
      "  },\n",
      "  y_dict={ paper=[736389, 1] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = data.x_dict['paper'][0].shape[0]\n",
    "hidden_dim = 512\n",
    "num_node_types = len(data.num_nodes_dict)\n",
    "num_edge_types = len(data.edge_index_dict)\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "dropout = 0.2\n",
    "classifier_output_dim = 349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Sequential(\n",
      "  (0): HGTModel(\n",
      "    (adapt_features): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=128, out_features=512, bias=True)\n",
      "    )\n",
      "    (hgt_layers): ModuleList(\n",
      "      (0-3): 4 x HGTLayer()\n",
      "    )\n",
      "    (drop): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (1): Classifier(n_hid=256, n_out=359)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "hgt_GNN = HGTModel(input_dim,                           # input_dim\n",
    "                   hidden_dim,                          # hidden_dim\n",
    "                   num_node_types,                      # num_node_types\n",
    "                   num_edge_types,                      # num_edge_types\n",
    "                   num_heads,                           # num_heads\n",
    "                   num_layers,                          # num_layers\n",
    "                   dropout,                             # dropout\n",
    "                   prev_norm = True,                    # normalization on all but last layer\n",
    "                   last_norm = False,                   # normalization on last layer\n",
    "                   use_rte = False)                     # use relative temporal encoding \n",
    "classifier = Classifier(256, 359)\n",
    "HGT_classifier = nn.Sequential(hgt_GNN, classifier)\n",
    "\n",
    "print(HGT_classifier)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(HGT_classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
