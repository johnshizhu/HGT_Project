{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Academic Graph Dataset Experiment\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code opens the Microsoft Academic Graph Dataset and trains HGT\n",
    "Based on code provided by original HGT paper\n",
    "'''\n",
    "import torch\n",
    "from sparse_hgt import *\n",
    "from hgt_utils import *\n",
    "from sparse_model import *\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.nodeproppred import Evaluator\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib as plt\n",
    "\n",
    "print(\"Microsoft Academic Graph Dataset Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Data Preprocessing\n",
      "\n",
      "Retrieving Data from Open Graph Benchmark ...\n",
      "... Retrieval complete\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data Preprocessing\n",
    "ogbn-mag only comes with paper node features, thus for other nodes types we take the average\n",
    "of connected paper nodes as input features. \n",
    "'''\n",
    "print(\"Begin Data Preprocessing\")\n",
    "print(\"\")\n",
    "print(\"Retrieving Data from Open Graph Benchmark ...\")\n",
    "\n",
    "# Get dataset using Pytorch Geometric Loader\n",
    "dataset = PygNodePropPredDataset(name='ogbn-mag')\n",
    "print(\"... Retrieval complete\")\n",
    "data = dataset[0] # pyg graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating edge lists into Graph object\n",
      "('author', 'affiliated_with', 'institution')\n",
      "('author', 'writes', 'paper')\n",
      "('paper', 'cites', 'paper')\n",
      "('paper', 'has_topic', 'field_of_study')\n",
      "\n",
      "Reformatting edge lists and computing node degrees\n",
      "institution author affiliated_with 8740\n",
      "author institution rev_affiliated_with 852987\n",
      "author paper rev_writes 1134649\n",
      "paper author writes 736389\n",
      "paper paper cites 629169\n",
      "paper paper rev_cites 617924\n",
      "paper field_of_study rev_has_topic 736389\n",
      "field_of_study paper has_topic 59965\n",
      "\n",
      "Constructing node feature vectors for each node type in graph\n",
      "author\n",
      "field_of_study\n",
      "institution\n",
      "paper\n",
      "\n",
      "Constructing Node features for institutions\n",
      "\n",
      "Splitting dataset into train, val and test\n",
      "\n",
      "Creating Masks\n",
      "\n",
      "Preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# Constructing Custom Graph\n",
    "graph, y, train_paper, valid_paper, test_paper = prepare_graph(data, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE PARAMETERS HERE\n",
    "n_batch = 32        # number of sampled graphs for each epoch\n",
    "batch_size = 128\n",
    "num_epochs = 3\n",
    "clip = 1.0\n",
    "sample_depth = 6\n",
    "sample_width = 520\n",
    "plot = False # True or false to plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\hgt_utils.py:422: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  node_feature = torch.FloatTensor(node_feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Sampling Done\n",
      "Starting Sampling...\n",
      "...Sampling Done\n",
      "Starting Sampling...\n",
      "...Sampling Done\n"
     ]
    }
   ],
   "source": [
    "# Get Training Data for num_epochs\n",
    "target_nodes = np.arange(len(graph.node_feature['paper']))\n",
    "datas_list = []\n",
    "\n",
    "for i in np.arange(num_epochs):\n",
    "    datas_list.append(get_n_batches_training_data(n_batch, graph, sample_depth, sample_width, target_nodes, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Sequential(\n",
      "  (0): sparseHGTModel(\n",
      "    (adapt_features): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=129, out_features=256, bias=True)\n",
      "    )\n",
      "    (hgt_layers): ModuleList(\n",
      "      (0-7): 8 x sparseHGTLayer()\n",
      "    )\n",
      "    (drop): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (1): Classifier(n_hid=256, n_out=349)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creating Model\n",
    "\n",
    "# Model parameters\n",
    "hidden_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "dropout = 0.2\n",
    "\n",
    "print(\"Creating Model\")\n",
    "hgt_GNN = sparseHGTModel(len(graph.node_feature['paper'][0]), # input_dim\n",
    "                   hidden_dim,                          # hidden_dim\n",
    "                   len(graph.get_types()),              # num_node_types\n",
    "                   len(graph.get_meta_graph()),         # num_edge_types\n",
    "                   num_heads,                           # num_heads\n",
    "                   num_layers,                          # num_layers\n",
    "                   dropout,                             # dropout\n",
    "                   prev_norm = True,                    # normalization on all but last layer\n",
    "                   last_norm = False,                   # normalization on last layer\n",
    "                   use_rte = False)                     # use relative temporal encoding \n",
    "classifier = Classifier(hidden_dim, graph.y.max()+1)\n",
    "model = nn.Sequential(hgt_GNN, classifier)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Optimizer, Scheduler, Loss, etc. \n",
    "criterion = nn.NLLLoss()\n",
    "evaluator = Evaluator(name='ogbn-mag')\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],     'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, eps=1e-06)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, pct_start=0.05, anneal_strategy='linear', final_div_factor=10,\\\n",
    "                        max_lr = 5e-4, total_steps = n_batch * num_epochs + 1)\n",
    "\n",
    "stats = []\n",
    "res = []\n",
    "best_val = 0\n",
    "train_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch is: 0 ---------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8081) must match the size of tensor b (808) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\sparse_mag_experiment.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/johns/OneDrive/Desktop/HGT_Project/HGT/sparse_mag_experiment.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m ylabel \u001b[39m=\u001b[39m data[\u001b[39m6\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/johns/OneDrive/Desktop/HGT_Project/HGT/sparse_mag_experiment.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Forward\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/johns/OneDrive/Desktop/HGT_Project/HGT/sparse_mag_experiment.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m node_rep \u001b[39m=\u001b[39m hgt_GNN\u001b[39m.\u001b[39;49mforward(node_feature, node_type, edge_index, edge_type, edge_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/johns/OneDrive/Desktop/HGT_Project/HGT/sparse_mag_experiment.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m ylabel \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(ylabel)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/johns/OneDrive/Desktop/HGT_Project/HGT/sparse_mag_experiment.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train_res  \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mforward(node_rep[:\u001b[39mlen\u001b[39m(ylabel)][train_mask])\n",
      "File \u001b[1;32mc:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\sparse_model.py:55\u001b[0m, in \u001b[0;36msparseHGTModel.forward\u001b[1;34m(self, node_feature, node_type, edge_index, edge_type, edge_time)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdel\u001b[39;00m result \u001b[39m# clear\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhgt_layers:\n\u001b[1;32m---> 55\u001b[0m     post_drop \u001b[39m=\u001b[39m layer(post_drop, node_type, edge_index, edge_type, edge_time)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m post_drop\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\sparse_hgt.py:139\u001b[0m, in \u001b[0;36msparseHGTLayer.forward\u001b[1;34m(self, node_input, node_type, edge_index, edge_type, edge_time)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, node_input, node_type, edge_index, edge_type, edge_time):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, \n\u001b[0;32m    140\u001b[0m                           node_input\u001b[39m=\u001b[39;49mnode_input,\n\u001b[0;32m    141\u001b[0m                           node_type\u001b[39m=\u001b[39;49mnode_type, \n\u001b[0;32m    142\u001b[0m                           edge_type\u001b[39m=\u001b[39;49medge_type, \n\u001b[0;32m    143\u001b[0m                           edge_time\u001b[39m=\u001b[39;49medge_time,\n\u001b[0;32m    144\u001b[0m                           target_node_input\u001b[39m=\u001b[39;49mnode_input,\n\u001b[0;32m    145\u001b[0m                           source_node_input\u001b[39m=\u001b[39;49mnode_input,\n\u001b[0;32m    146\u001b[0m                           target_node_type\u001b[39m=\u001b[39;49mnode_type,\n\u001b[0;32m    147\u001b[0m                           source_node_type\u001b[39m=\u001b[39;49mnode_type,\n\u001b[0;32m    148\u001b[0m                           edge_relations\u001b[39m=\u001b[39;49medge_index)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:463\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[1;32m--> 463\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[0;32m    464\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    465\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[1;32mc:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\sparse_hgt.py:226\u001b[0m, in \u001b[0;36msparseHGTLayer.message\u001b[1;34m(self, edge_index_i, target_node_input, source_node_input, target_node_type, source_node_type, edge_type, edge_time, edge_relations)\u001b[0m\n\u001b[0;32m    223\u001b[0m     source_node_rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb(source_node_rep, edge_time[meta_relation_mask])\n\u001b[0;32m    225\u001b[0m \u001b[39m# Heterogenous Mutual Attention                    \u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m res_attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhet_mutual_attention(target_node_rep, source_node_rep, key_source_linear, query_source_linear, edge_type_index)\n\u001b[0;32m    227\u001b[0m res_attention_tensor[meta_relation_mask] \u001b[39m=\u001b[39m res_attention\n\u001b[0;32m    229\u001b[0m \u001b[39m# Heterogenous Message Passing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\sparse_hgt.py:90\u001b[0m, in \u001b[0;36msparseHGTLayer.het_mutual_attention\u001b[1;34m(self, target_node_rep, source_node_rep, key_source_linear, query_source_linear, edge_type_index)\u001b[0m\n\u001b[0;32m     87\u001b[0m key_lin_attention_matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(key_lin_matrix\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrel_attention[edge_type_index])\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[39m# Dot product between new Key matrix and query, then include meta relation triplet tensor divided by root of head dim\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m res_attention \u001b[39m=\u001b[39m (query_lin_matrix \u001b[39m*\u001b[39;49m key_lin_attention_matrix)\u001b[39m.\u001b[39msum(dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrel_priority[edge_type_index] \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqrt_head_dim)\n\u001b[0;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m res_attention\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (8081) must match the size of tensor b (808) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "start_time = time.time()\n",
    "epoch_counter = 0\n",
    "total_training_time = 0\n",
    "\n",
    "for epoch in np.arange(num_epochs):\n",
    "    print(f'Current Epoch is: {epoch_counter} ---------------------')\n",
    "\n",
    "    # TRAINING\n",
    "    training_time_start = time.time()\n",
    "    model.train()\n",
    "    stat = []\n",
    "    for data in datas_list[epoch]:\n",
    "        node_feature = data[0]\n",
    "        node_type = data[1]\n",
    "        edge_time = data[2]\n",
    "        edge_index = data[3]\n",
    "        edge_type = data[4]\n",
    "        (train_mask, valid_mask, test_mask) = data[5]\n",
    "        ylabel = data[6]\n",
    "\n",
    "        # Forward\n",
    "        node_rep = hgt_GNN.forward(node_feature, node_type, edge_index, edge_type, edge_time)\n",
    "        ylabel = torch.LongTensor(ylabel)\n",
    "        train_res  = classifier.forward(node_rep[:len(ylabel)][train_mask])\n",
    "        valid_res  = classifier.forward(node_rep[:len(ylabel)][valid_mask])\n",
    "        test_res   = classifier.forward(node_rep[:len(ylabel)][test_mask])\n",
    "\n",
    "        train_loss = criterion(train_res, ylabel[train_mask])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_step += 1\n",
    "        scheduler.step(train_step)\n",
    "\n",
    "        train_acc  = evaluator.eval({\n",
    "                        'y_true': ylabel[train_mask].unsqueeze(-1),\n",
    "                        'y_pred': train_res.argmax(dim=1).unsqueeze(-1)\n",
    "                    })['acc']\n",
    "        valid_acc  = evaluator.eval({\n",
    "                        'y_true': ylabel[valid_mask].unsqueeze(-1),\n",
    "                        'y_pred': valid_res.argmax(dim=1).unsqueeze(-1)\n",
    "                    })['acc']\n",
    "        test_acc   = evaluator.eval({\n",
    "                        'y_true': ylabel[test_mask].unsqueeze(-1),\n",
    "                        'y_pred': test_res.argmax(dim=1).unsqueeze(-1)\n",
    "                    })['acc']\n",
    "        stat += [[train_loss.item(), train_acc, valid_acc, test_acc]]\n",
    "        del node_rep, train_loss, ylabel\n",
    "    print(f'train_acc: {train_acc}')\n",
    "    print(f'valid_acc: {valid_acc}')\n",
    "    print(f'test_acc: {test_acc}')\n",
    "    epoch_counter += 1\n",
    "    training_time_end = time.time()\n",
    "    elapsed_time = training_time_end - training_time_start\n",
    "    total_training_time += elapsed_time\n",
    "    print(\"\")\n",
    "stop_time = time.time()\n",
    "time_elapsed = stop_time - start_time\n",
    "print(f'TRAINING time elapsed is: {total_training_time}')\n",
    "print(f'time elapsed is: {time_elapsed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
