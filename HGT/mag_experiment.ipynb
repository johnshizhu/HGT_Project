{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Academic Graph Dataset Experiment\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code opens the Microsoft Academic Graph Dataset and trains HGT\n",
    "Based on code provided by original HGT paper\n",
    "'''\n",
    "import torch\n",
    "from hgt import *\n",
    "from hgt_utils import *\n",
    "from model import *\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.nodeproppred import Evaluator\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "\n",
    "print(\"Microsoft Academic Graph Dataset Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Data Preprocessing\n",
      "\n",
      "Retrieving Data from Open Graph Benchmark ...\n",
      "... Retrieval complete\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data Preprocessing\n",
    "ogbn-mag only comes with paper node features, thus for other nodes types we take the average\n",
    "of connected paper nodes as input features. \n",
    "'''\n",
    "print(\"Begin Data Preprocessing\")\n",
    "print(\"\")\n",
    "print(\"Retrieving Data from Open Graph Benchmark ...\")\n",
    "\n",
    "# Get dataset using Pytorch Geometric Loader\n",
    "dataset = PygNodePropPredDataset(name='ogbn-mag')\n",
    "print(\"... Retrieval complete\")\n",
    "data = dataset[0] # pyg graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating edge lists into Graph object\n",
      "('author', 'affiliated_with', 'institution')\n",
      "('author', 'writes', 'paper')\n",
      "('paper', 'cites', 'paper')\n",
      "('paper', 'has_topic', 'field_of_study')\n",
      "\n",
      "Reformatting edge lists and computing node degrees\n",
      "institution author affiliated_with 8740\n",
      "author institution rev_affiliated_with 852987\n",
      "author paper rev_writes 1134649\n",
      "paper author writes 736389\n",
      "paper paper cites 629169\n",
      "paper paper rev_cites 617924\n",
      "paper field_of_study rev_has_topic 736389\n",
      "field_of_study paper has_topic 59965\n",
      "\n",
      "Constructing node feature vectors for each node type in graph\n",
      "author\n",
      "field_of_study\n",
      "institution\n",
      "paper\n",
      "\n",
      "Constructing Node features for institutions\n",
      "\n",
      "Splitting dataset into train, val and test\n",
      "\n",
      "Creating Masks\n",
      "\n",
      "Preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(name='ogbn-mag')\n",
    "# Preparing Graph\n",
    "graph, y, train_paper, valid_paper, test_paper = prepare_graph(data, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add_edge', 'add_node', 'edge_list', 'get_meta_graph', 'get_types', 'node_bacward', 'node_feature', 'node_forward', 'test_mask', 'test_paper', 'times', 'train_mask', 'train_paper', 'update_node', 'valid_mask', 'valid_paper', 'y', 'years']\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "print(dir(graph))\n",
    "print(len(graph.node_feature['paper'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing data\n",
    "'''\n",
    "batch_number = 32 # number of sampled graphs for each epoch\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "num_workers = 8\n",
    "clip = 1.0\n",
    "sample_depth = 6\n",
    "sample_width = 520\n",
    "plot = False # True or false to plot data\n",
    "target_nodes = np.arange(len(graph.node_feature['paper']))\n",
    "\n",
    "stats = []\n",
    "result = []\n",
    "best_val = 0\n",
    "training_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample nodes:\n",
    "samp_nodes = np.random.choice(target_nodes, batch_size, replace = False)\n",
    "sample_depth = 6\n",
    "sample_width = 520           \n",
    "inp = {'paper': np.concatenate([samp_nodes, graph.years[samp_nodes]]).reshape(2, -1).transpose()}\n",
    "seed = randint()\n",
    "n_batch = 32\n",
    "batch_size = 128\n",
    "# node_feature, node_type, edge_time, edge_index, edge_type, (train_mask, valid_mask, test_mask), ylabel = ogbn_sample(seed, samp_nodes, graph, sample_depth, sample_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sampling...\n",
      "Batch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\OneDrive\\Desktop\\HGT_Project\\HGT\\hgt_utils.py:351: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  node_feature = torch.FloatTensor(node_feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0, complete\n",
      "Batch number: 1\n",
      "Batch Number: 1, complete\n",
      "Batch number: 2\n",
      "Batch Number: 2, complete\n",
      "Batch number: 3\n",
      "Batch Number: 3, complete\n",
      "Batch number: 4\n",
      "Batch Number: 4, complete\n",
      "Batch number: 5\n",
      "Batch Number: 5, complete\n",
      "Batch number: 6\n",
      "Batch Number: 6, complete\n",
      "Batch number: 7\n",
      "Batch Number: 7, complete\n",
      "Batch number: 8\n",
      "Batch Number: 8, complete\n",
      "Batch number: 9\n",
      "Batch Number: 9, complete\n",
      "Batch number: 10\n",
      "Batch Number: 10, complete\n",
      "Batch number: 11\n",
      "Batch Number: 11, complete\n",
      "Batch number: 12\n",
      "Batch Number: 12, complete\n",
      "Batch number: 13\n",
      "Batch Number: 13, complete\n",
      "Batch number: 14\n",
      "Batch Number: 14, complete\n",
      "Batch number: 15\n",
      "Batch Number: 15, complete\n",
      "Batch number: 16\n",
      "Batch Number: 16, complete\n",
      "Batch number: 17\n",
      "Batch Number: 17, complete\n",
      "Batch number: 18\n",
      "Batch Number: 18, complete\n",
      "Batch number: 19\n",
      "Batch Number: 19, complete\n",
      "Batch number: 20\n",
      "Batch Number: 20, complete\n",
      "Batch number: 21\n",
      "Batch Number: 21, complete\n",
      "Batch number: 22\n",
      "Batch Number: 22, complete\n",
      "Batch number: 23\n",
      "Batch Number: 23, complete\n",
      "Batch number: 24\n",
      "Batch Number: 24, complete\n",
      "Batch number: 25\n",
      "Batch Number: 25, complete\n",
      "Batch number: 26\n",
      "Batch Number: 26, complete\n",
      "Batch number: 27\n",
      "Batch Number: 27, complete\n",
      "Batch number: 28\n",
      "Batch Number: 28, complete\n",
      "Batch number: 29\n",
      "Batch Number: 29, complete\n",
      "Batch number: 30\n",
      "Batch Number: 30, complete\n",
      "Batch number: 31\n",
      "Batch Number: 31, complete\n",
      "...Preprocessing complete \n"
     ]
    }
   ],
   "source": [
    "# Sampling Data from MAG\n",
    "datas = []\n",
    "print(\"Starting Sampling...\")\n",
    "for batch_id in np.arange(n_batch):\n",
    "    print(f'Batch number: {batch_id}')\n",
    "    node_feature, node_type, edge_time, edge_index, edge_type, (train_mask, valid_mask, test_mask), ylabel = ogbn_sample(seed, samp_nodes, graph, sample_depth, sample_width)\n",
    "    p = (\n",
    "        node_feature,\n",
    "        node_type,\n",
    "        edge_time,\n",
    "        edge_index,\n",
    "        edge_type,\n",
    "        (train_mask, valid_mask, test_mask),\n",
    "        ylabel\n",
    "    )\n",
    "    datas.append(p)\n",
    "    print(f'Batch Number: {batch_id}, complete')\n",
    "print(\"...Preprocessing complete \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def het_mutual_attention(target_node_rep, source_node_rep, key_source_linear, query_source_linear, edge_type_index, num_heads, head_dim, rel_attention, rel_priority, sqrt_head_dim):\n",
    "    '''\n",
    "    Heterogeneous Mutual Attention calculation\n",
    "    Input:\n",
    "        - target_node_rep      - Node representation of target\n",
    "        - source_node_rep      - Node representation of source\n",
    "        - key_source_linear    - Linear projection of key source    (nn.ModuleList(), looped nn.Linear layers)\n",
    "        - query_source_linear  - Linear projection of query source  (nn.MOduleList(), looped nn.Linear layers)\n",
    "        - edge_type_index      - index\n",
    "    Output:\n",
    "        - res_attention - Tensor storing computed attention coefficients between source and target nodes. \n",
    "    '''\n",
    "    # Apply linear layers for Key (source) and Query (target)\n",
    "    print(target_node_rep.shape)\n",
    "    print(query_source_linear.weight.shape)\n",
    "\n",
    "    query_lin_matrix = query_source_linear(target_node_rep).view(-1, num_heads, head_dim)\n",
    "    key_lin_matrix = key_source_linear(source_node_rep).view(-1, num_heads, head_dim)\n",
    "\n",
    "\n",
    "    # Calculate Relation Attention with Key matrix\n",
    "    key_lin_attention_matrix = torch.bmm(key_lin_matrix.transpose(1,0), rel_attention[edge_type_index]).transpose(1,0)\n",
    "\n",
    "    # Dot product between new Key matrix and query, then include meta relation triplet tensor divided by root of head dim\n",
    "    res_attention = (query_lin_matrix * key_lin_attention_matrix).sum(dim = -1) * (rel_priority[edge_type_index] / sqrt_head_dim)\n",
    "\n",
    "    return res_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8587, 129])\n",
      "torch.Size([256, 129])\n"
     ]
    }
   ],
   "source": [
    "# Example heterogeneous mutual attention\n",
    "stat = []\n",
    "\n",
    "# p = (\n",
    "#     0 node_feature,\n",
    "#     1 node_type,\n",
    "#     2 edge_time,\n",
    "#     3 edge_index,     # An edge_index pair is the same index in the first and second tensors, edge between nodes of that index\n",
    "#     4 edge_type,      # There is an edge type associated with every edge_index \"pair\"\n",
    "#     5 (train_mask, valid_mask, test_mask),\n",
    "#     6 ylabel\n",
    "# )\n",
    "\n",
    "node_feature = datas[0][0]\n",
    "node_type = datas[0][1]\n",
    "edge_time = datas[0][2]\n",
    "edge_index = datas[0][3]\n",
    "edge_type = datas[0][4]\n",
    "\n",
    "\n",
    "num_heads = 8\n",
    "source_type_index = 0\n",
    "edge_type_index = 2\n",
    "target_type_index = 0\n",
    "\n",
    "num_edge_types = 8\n",
    "num_node_types = 4\n",
    "in_dim = 129\n",
    "out_dim = 256\n",
    "head_dim = out_dim // num_heads\n",
    "\n",
    "# edge_mask holds true for all edges of type edge_type_index\n",
    "edge_mask = (edge_type == int(edge_type_index))\n",
    "\n",
    "# create mask for all edges that have source node of type source_type_index\n",
    "source_nodes_mask = (node_type == int(source_type_index))\n",
    "source_nodes_indexes = source_nodes_mask.nonzero(as_tuple = True)[0] # holds all indexes where a node is of type source_node_type\n",
    "source_edges_mask = torch.isin(edge_index[0], source_nodes_indexes)\n",
    "\n",
    "# create mask for all edges that have target nod eof type target_type_index\n",
    "target_nodes_mask = (node_type == int(target_type_index))\n",
    "target_nodes_indexes = target_nodes_mask.nonzero(as_tuple = True)[0]\n",
    "target_edges_mask = torch.isin(edge_index[0], target_nodes_indexes)\n",
    "\n",
    "# Meta relation triple, True at indexes where typing matches up\n",
    "meta_relation_mask = edge_mask & source_edges_mask & target_edges_mask\n",
    "\n",
    "# apply meta_relation_mask on to get indexes of node_feature\n",
    "source_node_index_location = edge_index[0][meta_relation_mask]\n",
    "target_node_index_location = edge_index[1][meta_relation_mask]\n",
    "\n",
    "# get Node representations based on index_location\n",
    "source_node_rep = node_feature[source_node_index_location]\n",
    "target_node_rep = node_feature[target_node_index_location]\n",
    "\n",
    "key_lin_list = nn.ModuleList()\n",
    "value_lin_list = nn.ModuleList()\n",
    "query_lin_list = nn.ModuleList()\n",
    "\n",
    "for i in range(num_node_types):\n",
    "    key_lin_list.append(nn.Linear(in_dim, out_dim))\n",
    "    value_lin_list.append(nn.Linear(in_dim, out_dim))\n",
    "    query_lin_list.append(nn.Linear(in_dim, out_dim))\n",
    "\n",
    "rel_attention  = nn.Parameter(torch.Tensor(num_edge_types, num_heads, head_dim, head_dim))\n",
    "rel_priority   = nn.Parameter(torch.ones(num_edge_types, num_heads))\n",
    "sqrt_head_dim  = math.sqrt(head_dim)\n",
    "# het_mutual_attention(target_node_rep, source_node_rep, key_source_linear, query_source_linear, edge_type_index, num_heads, head_dim, rel_attention, rel_priority, sqrt_head_dim)\n",
    "glorot(rel_attention)\n",
    "\n",
    "key_source_linear = key_lin_list[source_type_index]\n",
    "value_source_linear = value_lin_list[source_type_index]\n",
    "query_source_linear = query_lin_list[target_type_index]\n",
    "\n",
    "target_node_rep = target_node_rep.to(torch.float32)\n",
    "\n",
    "output = het_mutual_attention(target_node_rep, source_node_rep, key_source_linear, query_source_linear, edge_type_index, num_heads, head_dim, rel_attention, rel_priority, sqrt_head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creating Model\n",
    "'''\n",
    "print(\"Creating Model\")\n",
    "print(len(graph.get_meta_graph()))\n",
    "hgt_GNN = HGTModel(len(graph.node_feature['paper'][0]), # input_dim\n",
    "                   256,                                 # hidden_dim\n",
    "                   len(graph.get_types()),              # num_node_types\n",
    "                   len(graph.get_meta_graph()),         # num_edge_types\n",
    "                   8,                                   # num_heads\n",
    "                   4,                                   # num_layers\n",
    "                   0.2,                                 # dropout\n",
    "                   prev_norm = True,                    # normalization on all but last layer\n",
    "                   last_norm = False,                   # normalization on last layer\n",
    "                   use_rte = False)                     # use relative temporal encoding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feature shape is: :torch.Size([10519, 129])\n",
      "PRE-NSERT shape is: torch.Size([10519, 256])\n",
      "PRE_DROP shape is (result): torch.Size([10519, 256])\n",
      "POST_DROP shape is: torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "AGGREGATION HAPPENING\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "AGGREGATION HAPPENING\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "AGGREGATION HAPPENING\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "torch.Size([10519, 256])\n",
      "AGGREGATION HAPPENING\n"
     ]
    }
   ],
   "source": [
    "print(f'node_feature shape is: :{node_feature.shape}')\n",
    "node_rep = hgt_GNN.forward(node_feature, node_type, edge_index, edge_type, edge_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10519, 256])\n",
      "tensor([[-1.1247, -0.0228,  0.2347,  ..., -0.7701, -0.6769, -1.3484],\n",
      "        [-0.8180, -1.8696,  0.5648,  ..., -1.0659, -0.6553, -1.8062],\n",
      "        [-1.0636, -1.7499,  0.1735,  ...,  0.1019,  0.0990, -0.8137],\n",
      "        ...,\n",
      "        [-1.8460, -1.1319, -2.3900,  ..., -0.9407,  0.0154,  2.1887],\n",
      "        [-2.3474, -0.2455, -1.5087,  ..., -0.4388,  1.0901,  1.9827],\n",
      "        [-1.8562, -0.3172, -0.6318,  ..., -0.3494,  0.6434,  2.3511]],\n",
      "       grad_fn=<IndexPutBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(node_rep.shape)\n",
    "print(node_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Negative Log Likelihood Loss\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "# # Get list of model parameters w/ associated names\n",
    "# parameters_optimizer = list(HGT_classifier.named_parameters())\n",
    "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params': [p for n, p in parameters_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#     {'params': [p for n, p in parameters_optimizer if any(nd in n for nd in no_decay)],     'weight_decay': 0.0}\n",
    "# ]\n",
    "# # AdamW optimizer w/specified parameter groups and epsilon value\n",
    "# optimizer = torch.optim.AdamW(optimizer_grouped_parameters, eps=1e-06)\n",
    "# # Create a OneCycleLR learning rate scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, pct_start=0.05, anneal_strategy='linear', final_div_factor=10,\\\n",
    "#                         max_lr = 5e-4, total_steps = batch_size * num_epochs + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
