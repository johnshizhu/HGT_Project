{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Academic Graph Dataset Experiment\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code opens the Microsoft Academic Graph Dataset and trains HGT\n",
    "Based on code provided by original HGT paper\n",
    "'''\n",
    "import torch\n",
    "from hgt import *\n",
    "from hgt_utils import *\n",
    "from local_access import *\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.nodeproppred import Evaluator\n",
    "from graph import Graph\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "print(\"Microsoft Academic Graph Dataset Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Preprocessing\n",
    "ogbn-mag only comes with paper node features, thus for other nodes types we take the average\n",
    "of connected paper nodes as input features. \n",
    "'''\n",
    "print(\"Begin Data Preprocessing\")\n",
    "print(\"\")\n",
    "print(\"Retrieving Data from Open Graph Benchmark ...\")\n",
    "\n",
    "# Get dataset using Pytorch Geometric Loader\n",
    "dataset = PygNodePropPredDataset(name='ogbn-mag')\n",
    "print(\"... Retrieval complete\")\n",
    "data = dataset[0] # pyg graph object\n",
    "evaluator = Evaluator(name='ogbn-mag')\n",
    "\n",
    "\n",
    "# Populating edge lists in Graph object based on edge_list\n",
    "print(\"Populating edge lists into Graph object\")\n",
    "edge_index_dict = data.edge_index_dict \n",
    "graph = Graph()\n",
    "edg = graph.edge_list\n",
    "years = data.node_year['paper'].t().numpy()[0]\n",
    "# for every type of edge relation i.e. ('author', 'affiliated_with', 'institution'), ...\n",
    "for key in edge_index_dict:\n",
    "    print(key) # print relation name\n",
    "    edges = edge_index_dict[key] \n",
    "    '''\n",
    "    tensor( [[      0,       1,       2,  ..., 1134645, 1134647, 1134648],\n",
    "             [    845,     996,    3197,  ...,    5189,    4668,    4668]]) example edges tensor\n",
    "    '''\n",
    "    # getting types of source, relation and edge ('author', 'affiliated_with', 'institution')\n",
    "    s_type, r_type, t_type = key[0], key[1], key[2]\n",
    "    elist = edg[t_type][s_type][r_type]\n",
    "    rlist = edg[s_type][t_type]['rev_' + r_type]\n",
    "    # adding year if the type is paper\n",
    "    for s_id, t_id in edges.t().tolist():\n",
    "        year = None\n",
    "        if s_type == 'paper':\n",
    "            year = years[s_id]\n",
    "        elif t_type == 'paper':\n",
    "            year = years[t_id]\n",
    "        elist[t_id][s_id] = year\n",
    "        rlist[s_id][t_id] = year\n",
    "\n",
    "# Reformatting edge list and computing node degrees\n",
    "print(\"Reformatting edge lists and computing node degrees\")\n",
    "edg = {}\n",
    "deg = {key : np.zeros(data.num_nodes_dict[key]) for key in data.num_nodes_dict}\n",
    "for k1 in graph.edge_list:\n",
    "    if k1 not in edg:\n",
    "        edg[k1] = {}\n",
    "    for k2 in graph.edge_list[k1]:\n",
    "        if k2 not in edg[k1]:\n",
    "            edg[k1][k2] = {}\n",
    "        for k3 in graph.edge_list[k1][k2]:\n",
    "            if k3 not in edg[k1][k2]:\n",
    "                edg[k1][k2][k3] = {}\n",
    "            for e1 in graph.edge_list[k1][k2][k3]:\n",
    "                if len(graph.edge_list[k1][k2][k3][e1]) == 0:\n",
    "                    continue\n",
    "\n",
    "                edg[k1][k2][k3][e1] = {}\n",
    "                for e2 in graph.edge_list[k1][k2][k3][e1]:\n",
    "                    edg[k1][k2][k3][e1][e2] = graph.edge_list[k1][k2][k3][e1][e2]\n",
    "                deg[k1][e1] += len(edg[k1][k2][k3][e1])\n",
    "            print(k1, k2, k3, len(edg[k1][k2][k3]))\n",
    "graph.edge_list = edg # inserting new edge list into Graph object\n",
    "\n",
    "# Constructing node feature vectors for each node type in graph\n",
    "print(\"Constructing node feature vectors for each node type in graph\")\n",
    "paper_node_features = data.x_dict['paper'].numpy() # data into numpy\n",
    "# append log degree to get full paper node features\n",
    "graph.node_feature['paper'] = np.concatenate((paper_node_features, np.log10(deg['paper'].reshape(-1, 1))), axis=-1)\n",
    "# These are node types: {'author': 1134649, 'field_of_study': 59965, 'institution': 8740, 'paper': 736389}\n",
    "for node_type in data.num_nodes_dict:\n",
    "    print(node_type)\n",
    "    if node_type not in ['paper', 'institution']:\n",
    "        i = []\n",
    "        for rel_type in graph.edge_list[node_type]['paper']:\n",
    "            for t in graph.edge_list[node_type]['paper'][rel_type]:\n",
    "                for s in graph.edge_list[node_type]['paper'][rel_type][t]:\n",
    "                    i += [[t,s]]\n",
    "            if len(i) == 0:\n",
    "                continue\n",
    "        i = np.array(i).T\n",
    "        v = np.ones(i.shape[1])\n",
    "        m = normalize(sp.coo_matrix((v, i), \\\n",
    "            shape=(data.num_nodes_dict[node_type], data.num_nodes_dict['paper'])))\n",
    "        out = m.dot(paper_node_features)\n",
    "        graph.node_feature[node_type] = np.concatenate((out, np.log10(deg[node_type].reshape(-1, 1))), axis=-1)\n",
    "\n",
    "# Contructing node feature vectors for institution nodes\n",
    "print(\"Constructing Node features for institutions\")    \n",
    "cv = graph.node_feature['author'][:, :-1]\n",
    "i = []\n",
    "for _rel in graph.edge_list['institution']['author']:\n",
    "    for j in graph.edge_list['institution']['author'][_rel]:\n",
    "        for t in graph.edge_list['institution']['author'][_rel][j]:\n",
    "            i += [[j, t]]\n",
    "i = np.array(i).T\n",
    "v = np.ones(i.shape[1])\n",
    "m = normalize(sp.coo_matrix((v, i), \\\n",
    "    shape=(data.num_nodes_dict['institution'], data.num_nodes_dict['author'])))\n",
    "out = m.dot(cv)\n",
    "graph.node_feature['institution'] = np.concatenate((out, np.log10(deg['institution'].reshape(-1, 1))), axis=-1)      \n",
    "\n",
    "# y_dict\n",
    "y = data.y_dict['paper'].t().numpy()[0]\n",
    "\n",
    "# Splitting dataset into training, validation and testing\n",
    "print(\"Splitting dataset into train, val and test\")\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_paper = split_idx['train']['paper'].numpy()\n",
    "valid_paper = split_idx['valid']['paper'].numpy()\n",
    "test_paper  = split_idx['test']['paper'].numpy()\n",
    "\n",
    "graph.y = y\n",
    "graph.train_paper = train_paper\n",
    "graph.valid_paper = valid_paper\n",
    "graph.test_paper  = test_paper\n",
    "graph.years       = years\n",
    "\n",
    "print(\"Creating Masks\")\n",
    "graph.train_mask = np.zeros(len(graph.node_feature['paper']), dtype=bool)\n",
    "graph.train_mask[graph.train_paper] = True\n",
    "\n",
    "graph.valid_mask = np.zeros(len(graph.node_feature['paper']), dtype=bool)\n",
    "graph.valid_mask[graph.valid_paper] = True\n",
    "\n",
    "graph.test_mask = np.zeros(len(graph.node_feature['paper']),  dtype=bool)\n",
    "graph.test_mask[graph.test_paper] = True\n",
    "\n",
    "# Preprocessing graph object is now complete\n",
    "print(\"Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating Model\n",
    "'''\n",
    "print(\"Creating Model\")\n",
    "hgt_GNN = HGTModel(len(graph.node_feature['paper'][0]), # input_dim\n",
    "                   256,                                 # hidden_dim\n",
    "                   len(graph.get_types()),              # num_node_types\n",
    "                   len(graph.get_meta_graph()),         # num_edge_types\n",
    "                   8,                                   # num_heads\n",
    "                   4,                                   # num_layers\n",
    "                   0.2,                                 # dropout\n",
    "                   prev_norm = True,                    # normalization on all but last layer\n",
    "                   last_norm = False,                   # normalization on last layer\n",
    "                   use_rte = True)                      # use relative temporal encoding\n",
    "classifier = Classifier(256, graph.y.max()+1)\n",
    "\n",
    "HGT_classifier = nn.Sequential(hgt_GNN, classifier)\n",
    "print(HGT_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
